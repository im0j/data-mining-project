{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datapath / 'dataset.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['ingredient_codes']), len(dataset['cuisine_codes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = MultiLabelBinarizer()\n",
    "encoder.fit([range(len(dataset['ingredient_codes']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = encoder.transform(dataset['X_train'])\n",
    "y_train = dataset['y_train']\n",
    "X_val = encoder.transform(dataset['X_cls_val'])\n",
    "y_val = dataset['y_cls_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "plt.matshow(confusion, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, y_pred), precision_score(y_val, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(C=0.1, max_iter=1000, n_jobs=-1)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "plt.matshow(confusion, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, y_pred), precision_score(y_val, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB(alpha=0.1)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "plt.matshow(confusion, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, y_pred), precision_score(y_val, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearSVC(C=0.03, max_iter=10000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "plt.matshow(confusion, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, y_pred), precision_score(y_val, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Path('..', 'save')\n",
    "savepath.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, p_dropout):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(in_feats, 300),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(300, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(300, out_feats),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        logits = self.linear_relu_stack(X)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float, device=device),\n",
    "    torch.tensor(y_train, dtype=torch.long, device=device),\n",
    "), shuffle=True, batch_size=8)\n",
    "valloader = DataLoader(TensorDataset(\n",
    "    torch.tensor(X_val, dtype=torch.float, device=device),\n",
    "    torch.tensor(y_val, dtype=torch.long, device=device),\n",
    "), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(\n",
    "    len(dataset['ingredient_codes']),\n",
    "    len(dataset['cuisine_codes']),\n",
    "    p_dropout=0.5\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(20, 40):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    net.train()\n",
    "    for X, y in dataloader:\n",
    "        y_prob = net(X)\n",
    "        loss = F.cross_entropy(y_prob, y)\n",
    "\n",
    "        train_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in valloader:\n",
    "            y_prob = net(X)\n",
    "            loss = F.cross_entropy(y_prob, y)\n",
    "\n",
    "            val_loss += loss\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    val_loss /= len(valloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(net.state_dict(), savepath / f'_300_300_{epoch}.pt')\n",
    "\n",
    "    print(f'Epoch {epoch} | Train loss: {train_loss} | Val loss: {val_loss}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(savepath / '_300_300_16.pt'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logits = net(torch.tensor(X_val, dtype=torch.float, device=device))\n",
    "y_pred = torch.argmax(y_logits, dim=-1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "plt.matshow(confusion, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, y_pred), precision_score(y_val, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification tasks baselines\n",
    "\n",
    "### RandomForestClassifier\n",
    "n_estimators|accuracy|precision\n",
    "---|---|---\n",
    "100|0.6973751274209989|0.7004341328977298\n",
    "200|**0.7027268093781855**|**0.7076188339183768**\n",
    "500|0.7010703363914373|0.7074596677137079\n",
    "\n",
    "### LogisticRegression\n",
    "C|accuracy|precision\n",
    "---|---|---\n",
    "0.1|0.7396788990825688|0.7464361349930922\n",
    "1|**0.7663098878695209**|**0.7641427551142695**\n",
    "3|0.758664627930683|0.7560706645009344\n",
    "10|0.7433741080530072|0.7413634213346916\n",
    "\n",
    "### MultinomialNB\n",
    "alpha|accuracy|precision\n",
    "---|---|---\n",
    "0|0.6980122324159022|0.7006106868535751\n",
    "0.1|0.7463047910295617|0.7552348477734679\n",
    "0.2|**0.7480886850152905**|**0.7560115265091186**\n",
    "0.3|0.7466870540265036|0.7541760647567084\n",
    "0.5|0.7394240570846076|0.7516239025446847\n",
    "1|0.71572375127421|0.7395414152003985\n",
    "2|0.6776248725790011|0.7195488889808616\n",
    "3|0.6526503567787971|0.7010370839331049\n",
    "\n",
    "### LinearSVC\n",
    "C|accuracy|precision\n",
    "---|---|---\n",
    "1|0.7529306829765545|0.7490671014362292\n",
    "0.3|0.7708970438328236|0.7674023585348014\n",
    "0.1|**0.7771406727828746**|**0.7753928549218926**\n",
    "0.03|0.7668195718654435|0.7681267914534073\n",
    "0.01|0.7464322120285423|0.7551715358401799\n",
    "\n",
    "\n",
    "### NeuralNet\n",
    "architecture|accuracy|precision\n",
    "---|---|---\n",
    "-100-|0.7819826707441386|0.7840162397622802\n",
    "-1000-|0.7882262996941896|0.7878159531920711\n",
    "-300-300-|0.7777777777777778|0.7826972381549467"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fe6ca38b531acce9745ef8eb50338f8e5d65d428710d131aa398878dc982c83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
